# MLSPstyletransfer
The stylizing process starts with downloading the two photos from the tweet and resizing them to 512x512 pixels. While this hurts quality, the two images need to have the same resolution, and this resolution is the maximum at which a result can be returned to the user in a reasonable amount of time. Another “image” is also created, but it is just a 512x512 pixel array of random noise. The algorithm then goes through the process of gradient descent to make the noise look like the two images that the user submitted. The final product is then uploaded to Amazon S3 and a tweet is sent notifying the user that their resulting image is ready to view. For more information on the algorithm, check out this [iPython Notebook](https://github.com/hnarayanan/artistic-style-transfer/blob/master/notebooks/6_Artistic_style_transfer_with_a_repurposed_VGG_Net_16.ipynb).
